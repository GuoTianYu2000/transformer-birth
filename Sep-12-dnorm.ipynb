{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import logging\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from probe_utils import *\n",
    "from plot_utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import List, Optional, Tuple\n",
    "import os\n",
    "# os.chdir(\"/data/tianyu_guo/birth\")\n",
    "from data import DataArgs, Dataset, iterate_batches, make_dataset\n",
    "from ihead_full_model import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = 'cuda:0'\n",
    "run_path_server = \"/data/tianyu/birth/gens/pre-iclr/dynamics/dormant_copy_long_train\"\n",
    "# run_path_server2=\"/data/tianyu_guo/birth/gens/special/dormant_copy_2\"\n",
    "model, cfg, x, y, ds, optim = load_model(run_path_local=\"/Users/guotianyu/GitHub/birth/gens/special/markov\", run_path_server=run_path_server, bos_num=1, train_steps=10000, delim=0, n_layers=3, n_heads=1, no_attn_norm=(), no_ffn_norm=(), no_attn=(), no_ffn=(), linear_ffn=(), with_data=True, with_optim=True, data_path_local=\"/Users/guotianyu/GitHub/birth/data\", data_path_server=\"/data/tianyu/birth/data\", device=device)\n",
    "hook = forward_hook([], '')\n",
    "\n",
    "grads, params, updates = {}, {}, {}\n",
    "optim.zero_grad()\n",
    "pred, outputs_list = model.modified_forward_with_hook(x, hook)\n",
    "\n",
    "grad_weight= torch.autograd.grad(outputs=outputs_list[0]['output'][0, 0, :].norm() ** 2, inputs=model.parameters(), create_graph=True, allow_unused=True)\n",
    "norm_grads = {}\n",
    "for (name, param), grad in zip(model.named_parameters(), grad_weight):\n",
    "    if grad is not None:\n",
    "        norm_grads[name] = grad\n",
    "\n",
    "loss = F.cross_entropy(pred.flatten(0, 1), y.flatten(0, 1))\n",
    "loss.backward()\n",
    "for name, param in model.named_parameters():\n",
    "    grads[name] = param.grad.detach().clone()\n",
    "    params[name] = param.detach().clone()\n",
    "optim.step()\n",
    "for name, param in model.named_parameters():\n",
    "    updates[name] = param.detach().clone() - params[name]\n",
    "probs = get_oracle_predicts(x, ds)\n",
    "triggers_pos = ds.get_triggers_pos(x.to('cpu'))\n",
    "risk = get_risk(probs, pred, predict_in_logits=True, triggers_pos=triggers_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_contributes = {}\n",
    "for name, grad in norm_grads.items():\n",
    "    norm_contributes[name] = (grad * updates[name]).sum().cpu().detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_copy = grads.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
